\documentclass[11pt]{article}
\usepackage{colacl}
\sloppy

\title{COMP90049 Project II Report}
\author{Clement Poh cjpoh 269508}

\begin{document}
\maketitle


\begin{abstract}

Text categorisation is a machine learning process that attempts to classify text
documents in to different categories or genres. This paper explores the process
of text categorisation from feature extraction with tf * idf values, to
classification with random forests and a cursory attempt using support vector
machines.

\end{abstract}


\section{Introduction}

Document classification and text categorisation is the task of classifying text
documents into a set of predefined categories. Traditionally classification was
in the province of library sciences. With the advent of computer systems and the
internet and the subsequent explosion of information, methods of automatically
categorising the information effectively are an active field of research in
computer science. Modern applications of categorisation are used searching and
spam filtering.

In this report, modern concepts from computer science are applied to a problem
already solved a long ago in library science; the classification of classics.

\section{Aim}

The aim of this report is to develop a text categorisation system to classify a
collection of books. The system is provided with three hundred books to be
trained on, to generate a feature set that is used to predict the categories of
another hundred books.

\section{Approach}

The system is split into four parts. The former two parts are responsible for
feature extraction and selection. The latter two are for classification.

The first extractor extracts tokens and other data from the training documents.
It analyses the data determines the relevant features to be used for the
classifiers, then outputs the training vectors for the classifiers. 

The second extractor reads the test data, tokenises it and creates the feature
vectors for the test data according to the analysis carried out by the training
extractor. The output specifications for the two extractors are exactly the
same. So they could be used interchangeably.

The classifiers are completely independent of each other, but are made to be
compatible with the feature vectors created by the extractors. The first is is a
random tree classifier. The second is a support vector machine classifier.

\subsection{Feature Selection}

The features used for classification are the top N unique words that are
determined to be indicative of category, two thousand by default. In
addition to these, the length of the book, and the number of unique words as
well as the length of the author's name is also used, if it can be found. 

The training extractor attempts to tokenise each book, keeping track of: total
number of words; total unique words; category; word; and each word's term
frequency; inserting them into a database. Then a list is created with each
word's term frequency calculated over the categories it is found in.

At the same time a list of words is created populated with words that appear in
more than M books, ten by default, and their respective inverse document
frequencies. 

These two lists are crossed, and the tf*idfs for each word, in each category are
calculated. The idea is that words in the resultant table with high tf*idf
scores occur in many books, but are sufficiently rare that they can be used to
indicate category. Words with low scores occur in all the books, and are
therefore discarded.

The top N (as specified above) words of this table are then chosen to be used as
variables for the feature vector as inputs to the classifiers.

This table is then naturally joined with all the books to create the training
feature vector, which is then processed and written out as a csv file.

The test extractor reads each of the files to be predicted, searching for the
variables to be used in the feature vector, and outputs the result of this to a
csv file.

\subsection{Categorisation}

Random forests and support vector machines are powerful classification
techniques so were chosen as classifiers. The classifiers were implemented using
the python package sklearn.

Both classifiers take the same data sets as input and write to the same output
specification, so can be used interchangeably. They both output the file names;
titles and authors if they can be found; the actual category; predicted
category; and predicted probabilities for each category are then written to a
csv file.

The random forest classifier creates a random forest of T trees, one hundred by
default, considering F features, one hundred by default, to fit the training
data. It is then used to predict the categories of the test data, and then
outputs its predictions. It performed superbly.

In much the same way the support vector machine classifier attempts to fit the
training data, then predict the test data. It performed very poorly.  The
original intention was to combine the two classifiers into a better hybrid
classifier; however, due to the poor performance of the svm classifier, the plan
was discontinued.

\section{Results}

With 1000 variables, considering 30 features per split, and words in only more
than one book, the random forest classifier predicted the categories of 80 out
of 100 files on its first run. Due to the random nature of the forest, its
accuracy varies. In subsequent early runs, it was found that it would vary
between 76 to 81 correct.

Running the classifier with 500 trees; which consider 300 features at each
split; with 2000 variables, with words that appear in greater than 10 books, the
random forest can consistently achieve 88 to 90 correct documents.

The support vector machine classifier performs abysmally, consistently achieving
an accuracy of only 46 out of 100.

\section{Analysis}

\section{Discussion}

Couldn't parse chinese book.
Originally wanted to use author's name
Wanted to use phrases
stemming
Important variables.
Should get top 125 of each.
remove the gutenberg header and footers.

\section{Conclusions}

Concluding text.

\bibliographystyle{acl}
\bibliography{sample}

\end{document}
